{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpDictionaries import PosMapper, PosList, Contraction_Dictionary1, stop_words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re, nltk\n",
    "from nltk.corpus import wordnet\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries for cleaning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dictionary includes contractions and their associated expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "Contraction_Dictionary1 = {\n",
    "    \"ain/t\": \"is not\", \"aren/t\": \"are not\", \"can/t\": \"can not\", \"can/t/ve\": \"can not have\", \"cause\": \"because\", \"could/ve\": \"could have\",\n",
    "    \"couldn/t\": \"could not\", \"couldn/t/ve\": \"could not have\", \"didn/t\": \"did not\", \"doesn/t\": \"does not\", \"don/t\": \"do not\", \"hadn/t\": \"had not\",\n",
    "    \"hadn/t/ve\": \"had not have\", \"hasn/t\": \"has not\", \"haven/t\": \"have not\", \"he/d\": \"he would\", \"he/d/ve\": \"he would have\", \"he/ll\": \"he will\",\n",
    "    \"he/ll/ve\": \"he he will have\", \"he/s\": \"he is\", \"how/d\": \"how did\", \"how/d/y\": \"how do you\", \"how/ll\": \"how will\", \"how/s\": \"how is\",\n",
    "    \"I/d\": \"I would\", \"I/d/ve\": \"I would have\", \"I/ll\": \"I will\", \"I/ll/ve\": \"I will have\", \"I/m\": \"I am\", \"I/ve\": \"I have\", \"i/d\": \"i would\",\n",
    "    \"i/d/ve\": \"i would have\", \"i/ll\": \"i will\", \"i/ll/ve\": \"i will have\", \"i/m\": \"i am\", \"i/ve\": \"i have\", \"isn/t\": \"is not\", \"it/d\": \"it would\",\n",
    "    \"it/d/ve\": \"it would have\", \"it/ll\": \"it will\", \"it/ll/ve\": \"it will have\", \"it/s\": \"it is\", \"let/s\": \"let us\", \"ma/am\": \"madam\", \"mayn/t\": \"may not\",\n",
    "    \"might/ve\": \"might have\", \"mightn/t\": \"might not\", \"mightn/t/ve\": \"might not have\", \"must/ve\": \"must have\", \"mustn/t\": \"must not\", \"mustn/t/ve\": \"must not have\",\n",
    "    \"needn/t\": \"need not\", \"needn/t/ve\": \"need not have\", \"o/clock\": \"of the clock\", \"oughtn/t\": \"ought not\", \"oughtn/t/ve\": \"ought not have\", \"shan/t\": \"shall not\",\n",
    "    \"sha/n/t\": \"shall not\", \"shan/t/ve\": \"shall not have\", \"she/d\": \"she would\", \"she/d/ve\": \"she would have\", \"she/ll\": \"she will\", \"she/ll/ve\": \"she will have\",\n",
    "    \"she/s\": \"she is\", \"should/ve\": \"should have\", \"shouldn/t\": \"should not\", \"shouldn/t/ve\": \"should not have\", \"so/ve\": \"so have\", \"so/s\": \"so as\",\n",
    "    \"that/d\": \"that would\", \"that/d/ve\": \"that would have\", \"that/s\": \"that is\", \"there/d\": \"there would\", \"there/d/ve\": \"there would have\",\n",
    "    \"there/s\": \"there is\", \"they/d\": \"they would\", \"they/d/ve\": \"they would have\", \"they/ll\": \"they will\", \"they/ll/ve\": \"they will have\", \"they/re\": \"they are\",\n",
    "    \"they/ve\": \"they have\", \"to/ve\": \"to have\", \"wasn/t\": \"was not\", \"we/d\": \"we would\", \"we/d/ve\": \"we would have\", \"we/ll\": \"we will\", \"we/ll/ve\": \"we will have\", \n",
    "    \"we/re\": \"we are\", \"we/ve\": \"we have\", \"weren/t\": \"were not\", \"what/ll\": \"what will\", \"what/ll/ve\": \"what will have\",\"what/re\": \"what are\", \"what/s\": \"what is\", \n",
    "    \"what/ve\": \"what have\", \"when/s\": \"when is\", \"when/ve\": \"when have\", \"where/d\": \"where did\", \"where/s\": \"where is\", \"where/ve\": \"where have\",\n",
    "    \"who/ll\": \"who will\", \"who/ll/ve\": \"who will have\", \"who/s\": \"who is\", \"who/ve\": \"who have\", \"why/s\": \"why is\", \"why/ve\": \"why have\", \"will/ve\": \"will have\", \n",
    "    \"won/t\": \"will not\",\"won/t/ve\": \"will not have\", \"would/ve\": \"would have\", \"wouldn/t\": \"would not\", \"wouldn/t/ve\": \"would not have\", \"y/all\": \"you all\",\n",
    "    \"y/all/d\": \"you all would\", \"y/all/d/ve\": \"you all would have\", \"y/all/re\": \"you all are\", \"y/all/ve\": \"you all have\", \"you/d\": \"you would\",\n",
    "    \"you/d/ve\": \"you would have\", \"you/ll\": \"you will\", \"you/ll/ve\": \"you will have\", \"you/re\": \"you are\", \"you/ve\": \"you have\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list contains an edited list of stopwords, with all negation words (e.g. 'no', 'never', 'not') excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words =['i','me','my','myself','we','our','ours','ourselves','you','your','yours','yourself',\n",
    "            'yourselves','he','him','his','himself','she','her','hers','herself','it','its','itself',\n",
    "            'they','them','their','theirs','themselves','what','which','who','whom','this','that',\n",
    "            'these','those','am','is','are','was','were','be','been','being','have','has','had',\n",
    "            'having','do','does','did','doing','a','an','the','and','but','if','or','because','as',\n",
    "            'until','while','of','at','by','for','with','about','against','between','into','through',\n",
    "            'during','before','after','above','below','to','from','up','down','in','out','on','off',\n",
    "            'over','under','again','further','then','once','here','there','when','where','why','how',\n",
    "            'all','any','both','each','few','more','most','other','some','such',\n",
    "            'only','own','same','so','than','too','very','can','will','just','should',\n",
    "            'now','uses','use','using','used','one','also']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second list contains the nltk.wordnet labelling convertion for verbs, adjectives, nouns and adverbs. The purpose of this list is to only lemmatize words that are POS (part-of-speech) tagged with these labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "PosList =[\"JJ\",\"JJR\",\"JJS\",\"NN\",\"NNS\",\"NNP\",\"NNPS\",\"RB\",\n",
    "          \"RBR\",\"RBS\",\"VB\",\"VBD\",\"VBG\",\"VBN\",\"VBP\",\"VBZ\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second dictionary uses the POS tag label as a key to refer to the root/lemma of a word. The purpose of this is to identify words with these POS tags and lemmatize them to their root lemma. E.g. 'running' --> 'run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "PosMapper = {\n",
    "\"JJ\": wordnet.ADJ,\n",
    "\"JJR\": wordnet.ADJ,\n",
    "\"JJS\": wordnet.ADJ,\n",
    "\"NN\": wordnet.NOUN,\n",
    "\"NNS\": wordnet.NOUN,\n",
    "\"NNP\": wordnet.NOUN,\n",
    "\"NNPS\": wordnet.NOUN,\n",
    "\"RB\": wordnet.ADV,\n",
    "\"RBR\": wordnet.ADV,\n",
    "\"RBS\": wordnet.ADV,\n",
    "\"VB\": wordnet.VERB,\n",
    "\"VBD\": wordnet.VERB,\n",
    "\"VBG\": wordnet.VERB,\n",
    "\"VBN\": wordnet.VERB,\n",
    "\"VBP\": wordnet.VERB,\n",
    "\"VBZ\": wordnet.VERB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Innitialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text normalization/standardization method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method normalizes the text into a coherent format for matching\n",
    "def standardize_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.lower() # Convert to lowercase\n",
    "    df[text_field] = df[text_field].str.replace('http','') # removing urls is useful to make vocabulary small as possible\n",
    "    df[text_field] = df[text_field].str.replace('com', '') # same as above.\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[^A-Za-z0-9(),!?@\\`\\\"\\_\\n]\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\", \"at\") #  replacing at sign for a word\n",
    "    df[text_field] = df[text_field].str.replace(\".\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(\",\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(\"-\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(\"(\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(\")\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace('\"', \" \")\n",
    "    df[text_field] = df[text_field].str.replace(\"?\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(\"!\", \"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contractions Expansion Prep\n",
    "In the data, contraction words such as wouldn't are noted as 'wouldn`t' ` which is a different character to the normal apostrophe. Therefore each instance is changed to a '/' in order to match contractions to the contraction dictionary equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method strips the ` and changes is to / in order to match contractions.\n",
    "def contractionPrep(df, text_field):\n",
    "    df[text_field] = df[text_field].str.lstrip(' ')\n",
    "    df[text_field] = df[text_field].str.replace(\"`\", '/')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contraction Expansion Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method expands all contractions to their original format\n",
    "def expand_contractions(text, contraction_mapping=Contraction_Dictionary2):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisation Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(x):\n",
    "    listOfTokens = []\n",
    "    for text in x:\n",
    "        text = str(text)\n",
    "        text = word_tokenize(text)\n",
    "        listOfTokens.append(text)\n",
    "    return listOfTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singleletter removal Method\n",
    "After an innitial inspection into word frequency, single letter words were very frequent and didnt seem to contribute much semantic meaning the tweets, so were therefore removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleLetterRemoval(list_object):\n",
    "    listOfTokens = []\n",
    "    for tweet in list_object:\n",
    "        temp = []\n",
    "        for word in tweet:\n",
    "            if len(word) > 1:\n",
    "                temp.append(word)\n",
    "        listOfTokens.append(temp)\n",
    "    return listOfTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number Removal Method\n",
    "Similarly to single letters, numbers dont contribute much meaning to the polarity of a tweet and so therefore removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberRemoval(list_object):\n",
    "    listOfTokens = []\n",
    "    for tweet in list_object:\n",
    "        temp = []\n",
    "        for word in tweet:\n",
    "            if not word.isnumeric():\n",
    "                temp.append(word)\n",
    "        listOfTokens.append(temp)\n",
    "    return listOfTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword Removal Method\n",
    "Stopwords are the most frequent words in the corpus and only create noise for the classifier so were therefore removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordRemoval(list_object):\n",
    "    listOfTokens = []\n",
    "    for tweet in list_object:\n",
    "        temp = []\n",
    "        for word in tweet:\n",
    "            if not word in stop_words:\n",
    "                temp.append(word)\n",
    "        listOfTokens.append(temp)\n",
    "    return listOfTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization Method\n",
    "Calls the Pos list and dictionary to return certain words into their root lemma format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(list_object):\n",
    "    tags = []\n",
    "    for words in list_object:\n",
    "        posTupples = nltk.pos_tag(words)\n",
    "        text = [lemmatizer.lemmatize(k[0], pos=PosMapper.get(k[1])) if k[1] in PosList else k[0] for k in posTupples]\n",
    "        tags.append(text)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in dataset and clean it.\n",
    "In order to compare the raw dataset to the cleaned version, two datasets are created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data to clean\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "#Read in raw dataset to test later\n",
    "data2 = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'selected text' column\n",
    "data = data.drop(columns='selected_text')\n",
    "data2 = data2.drop(columns='selected_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize datasets\n",
    "Each dataset is standardized (puntuation removed, converted to lower case, url-like stuff removed etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>i`d have responded  if i were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of       why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  cb774db0d1                i`d have responded  if i were going   neutral\n",
       "1  549e992a42         sooo sad i will miss you here in san diego  negative\n",
       "2  088c60f138                          my boss is bullying me     negative\n",
       "3  9642c003ef                      what interview leave me alone  negative\n",
       "4  358bd9e861   sons of       why couldn`t they put them on t...  negative"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize Text\n",
    "data = standardize_text(data,'text')\n",
    "data2 = standardize_text(data2,'text')\n",
    "data2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand contractions\n",
    "Only the dataset that is being cleaned calls these methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data ready for Contraction Expansion\n",
    "data = contractionPrep(data,'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>i would have responded  if i were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of       why could not they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  cb774db0d1            i would have responded  if i were going   neutral\n",
       "1  549e992a42         sooo sad i will miss you here in san diego  negative\n",
       "2  088c60f138                          my boss is bullying me     negative\n",
       "3  9642c003ef                      what interview leave me alone  negative\n",
       "4  358bd9e861  sons of       why could not they put them on t...  negative"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expand Contractions\n",
    "cleanedData = [expand_contractions(str(tweet)) for tweet in data['text']]\n",
    "data['text'] = cleanedData\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inspecting the results there were still some square brackets remaining as part of some words so these needed to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip remaining / from data\n",
    "data['text'] = data['text'].str.replace('/', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Data\n",
    "This is applied to both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize Data\n",
    "tweets = data['text'].tolist()\n",
    "tokenizedData = tokenizer(tweets)\n",
    "data['text'] = tokenizedData\n",
    "\n",
    "#Tokenize raw dataset without cleaning methods\n",
    "tweets2 = data2['text'].tolist()\n",
    "tokenizedData2 = tokenizer(tweets2)\n",
    "data2['text'] = tokenizedData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>[i, `, d, have, responded, if, i, were, going]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  cb774db0d1     [i, `, d, have, responded, if, i, were, going]   neutral\n",
       "1  549e992a42  [sooo, sad, i, will, miss, you, here, in, san,...  negative"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>[i, would, have, responded, if, i, were, going]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  cb774db0d1    [i, would, have, responded, if, i, were, going]   neutral\n",
       "1  549e992a42  [sooo, sad, i, will, miss, you, here, in, san,...  negative"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call rest of cleaning methods on the dataset that is being cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>[would, responded, going]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>[boss, bullying]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>[sons, could, not, put, releases, already, bou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  cb774db0d1                          [would, responded, going]   neutral\n",
       "1  549e992a42                      [sooo, sad, miss, san, diego]  negative\n",
       "2  088c60f138                                   [boss, bullying]  negative\n",
       "3  9642c003ef                          [interview, leave, alone]  negative\n",
       "4  358bd9e861  [sons, could, not, put, releases, already, bou...  negative"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#single letter removal:\n",
    "tweetData = data['text'].tolist()\n",
    "slRemoved = singleLetterRemoval(tweetData)\n",
    "data['text'] = slRemoved\n",
    "\n",
    "#number removal\n",
    "tweetData = data['text'].tolist()\n",
    "nRemoved = numberRemoval(tweetData)\n",
    "data['text'] = nRemoved\n",
    "\n",
    "#stopword removal\n",
    "tweetData = data['text'].tolist()\n",
    "noiseRemoved = stopwordRemoval(tweetData)\n",
    "data['text'] = noiseRemoved\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize the cleaned Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>[would, respond, go]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>[boss, bully]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>[son, could, not, put, release, already, buy]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                           text sentiment\n",
       "0  cb774db0d1                           [would, respond, go]   neutral\n",
       "1  549e992a42                  [sooo, sad, miss, san, diego]  negative\n",
       "2  088c60f138                                  [boss, bully]  negative\n",
       "3  9642c003ef                      [interview, leave, alone]  negative\n",
       "4  358bd9e861  [son, could, not, put, release, already, buy]  negative"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Lemmatize Data\n",
    "tweetData = data['text'].tolist()\n",
    "lemmatizedData = lemma(tweetData)\n",
    "data['text'] = lemmatizedData\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>[would, respond, go]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>[boss, bully]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>[son, could, not, put, release, already, buy]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                           text sentiment\n",
       "0  cb774db0d1                           [would, respond, go]   neutral\n",
       "1  549e992a42                  [sooo, sad, miss, san, diego]  negative\n",
       "2  088c60f138                                  [boss, bully]  negative\n",
       "3  9642c003ef                      [interview, leave, alone]  negative\n",
       "4  358bd9e861  [son, could, not, put, release, already, buy]  negative"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5) # cleanDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>[i, `, d, have, responded, if, i, were, going]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>[sons, of, why, couldn, `, t, they, put, them,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  cb774db0d1     [i, `, d, have, responded, if, i, were, going]   neutral\n",
       "1  549e992a42  [sooo, sad, i, will, miss, you, here, in, san,...  negative\n",
       "2  088c60f138                       [my, boss, is, bullying, me]  negative\n",
       "3  9642c003ef                [what, interview, leave, me, alone]  negative\n",
       "4  358bd9e861  [sons, of, why, couldn, `, t, they, put, them,...  negative"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head(5) # rawDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export dataframes to csv files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to CSV\n",
    "data.to_csv(r'C:\\Users\\Alex\\Desktop\\cleanedData.csv', index=False)\n",
    "data2.to_csv(r'C:\\Users\\Alex\\Desktop\\rawData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
