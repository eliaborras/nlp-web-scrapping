{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data: basic clean \n",
    "# Vectorizations using bag of words technique \n",
    "# vectorizer from sklearn CountVectorizer\n",
    "# Model Classifier: Support Vector Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/processed/basic_clean.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>would responded going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad miss san diego</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>boss bullying</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>interview leave alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons could put releases already bought</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish could see denver husband lost job afford</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>wondered rake client made clear net force devs...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>yay good enjoy break probably need hectic week...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>worth</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>flirting going atg smiles yay hugs</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text sentiment\n",
       "0      cb774db0d1                              would responded going   neutral\n",
       "1      549e992a42                            sooo sad miss san diego  negative\n",
       "2      088c60f138                                      boss bullying  negative\n",
       "3      9642c003ef                              interview leave alone  negative\n",
       "4      358bd9e861             sons could put releases already bought  negative\n",
       "...           ...                                                ...       ...\n",
       "27476  4eac33d1c0      wish could see denver husband lost job afford  negative\n",
       "27477  4f4c4fc327  wondered rake client made clear net force devs...  negative\n",
       "27478  f67aae2310  yay good enjoy break probably need hectic week...  positive\n",
       "27479  ed167662a5                                              worth  positive\n",
       "27480  6f7127d9d7                 flirting going atg smiles yay hugs   neutral\n",
       "\n",
       "[27481 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing nan cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "X = df['text']\n",
    "Y = df['sentiment']\n",
    "# Train test split\n",
    "X_train, x_test, Y_train, y_test = train_test_split(X, Y, random_state=42)\n",
    "\n",
    "with mlflow.start_run(run_name='suport_vector_clasifier'):\n",
    "    mlflow.log_param('file name', filename.split(\"/\")[-1])\n",
    "    try:\n",
    "        \n",
    "        count_vectorizer = CountVectorizer(stop_words='english', strip_accents='ascii', lowercase=True, max_features=25000)\n",
    "        svm = SVC(probability=True)\n",
    "    except ValueError: \n",
    "        logging.log(40,\" Error encountered in model instanciation.\".format(item))\n",
    "    \n",
    "    logging.info(\" Model instances created\")\n",
    "    # creating a pipeline\n",
    "    pipe = Pipeline(steps = [('vectorizer', count_vectorizer),\n",
    "                             ('svm_model', svm)])\n",
    "    \n",
    "    logging.info(\" Pipeline created.\")\n",
    "    \n",
    "    pipe.fit(X_train, Y_train)\n",
    "    log_params = [mlflow.log_param(key, value) for key, value in pipe.get_params().items() if '__' in key]\n",
    "    logging.info(\" Logged params.\")\n",
    "    \n",
    "    # Getting predicions \n",
    "    predictions = pipe.predict(x_test)\n",
    "    logging.info(\" Predictions out.\")\n",
    "    \n",
    "    # metrics \n",
    "    metrics_ = {'accuracy': accuracy_score,\n",
    "                'balanced_accuracy': metrics.balanced_accuracy_score,\n",
    "              #  'average_precision': metrics.average_precision_score,\n",
    "              #  'precission': metrics.precision_score,\n",
    "                'recall': metrics.recall_score,\n",
    "               }\n",
    "    \n",
    "    \n",
    "    for metric, func in metrics_.items():\n",
    "        try:\n",
    "            result = func(y_test, predictions)\n",
    "            print(f\"{metric} = {result}\")\n",
    "            mlflow.log_metric(metric, result)\n",
    "        except ValueError:\n",
    "            logging.log(40, f\"Not logged metric {metric}.\")\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    logging.info(\" Metrics logged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred = pd.DataFrame({'y_true':y_test, 'y_pred':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14833</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14586</th>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17108</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20881</th>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12488</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26978</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21778</th>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13860</th>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6850 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         y_true    y_pred\n",
       "14833   neutral   neutral\n",
       "14586  negative   neutral\n",
       "17108   neutral   neutral\n",
       "20881  negative   neutral\n",
       "3391    neutral   neutral\n",
       "...         ...       ...\n",
       "4223   negative  negative\n",
       "12488  negative  negative\n",
       "26978  positive  positive\n",
       "21778   neutral   neutral\n",
       "13860  positive   neutral\n",
       "\n",
       "[6850 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy archived: 0.69 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy archived: {0} %\".format( round(accuracy_score(real_pred['y_true'],real_pred['y_pred']), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.53      0.63      1970\n",
      "     neutral       0.61      0.82      0.70      2737\n",
      "    positive       0.79      0.69      0.73      2143\n",
      "\n",
      "    accuracy                           0.69      6850\n",
      "   macro avg       0.73      0.68      0.69      6850\n",
      "weighted avg       0.72      0.69      0.69      6850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(real_pred['y_true'],real_pred['y_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(predicted, Negative)</th>\n",
       "      <th>(predicted, Neutral)</th>\n",
       "      <th>(predicted, Positive)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(Actuals, Negative)</th>\n",
       "      <td>1038</td>\n",
       "      <td>816</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Actuals, Neutral)</th>\n",
       "      <td>229</td>\n",
       "      <td>2238</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Actuals, Positive)</th>\n",
       "      <td>46</td>\n",
       "      <td>629</td>\n",
       "      <td>1468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     (predicted, Negative)  (predicted, Neutral)  \\\n",
       "(Actuals, Negative)                   1038                   816   \n",
       "(Actuals, Neutral)                     229                  2238   \n",
       "(Actuals, Positive)                     46                   629   \n",
       "\n",
       "                     (predicted, Positive)  \n",
       "(Actuals, Negative)                    116  \n",
       "(Actuals, Neutral)                     270  \n",
       "(Actuals, Positive)                   1468  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(real_pred['y_true'],real_pred['y_pred']), index=[('Actuals','Negative'), ('Actuals','Neutral'), ('Actuals','Positive')], \n",
    "            columns=[('predicted','Negative'), ('predicted','Neutral'), ('predicted','Positive')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
